Cross modality deformable segmentation using hierarchical clustering and learning. Segmentation of anatomical objects is always a fundamental task for various clinical applications. Although many automatic segmentation methods have been designed to segment specific anatomical objects in a given imaging modality, a more generic solution that is directly applicable to different imaging modalities and different deformable surfaces is desired, if attainable. In this paper, we propose such a framework, which learns from examples the spatially adaptive appearance and shape of a 3D surface (either open or closed). The application to a new object/surface in a new modality requires only the annotation of training examples. Key contributions of our method include: (1) an automatic clustering and learning algorithm to capture the spatial distribution of appearance similarities/variations on the 3D surface. More specifically, the model vertices are hierarchically clustered into a set of anatomical primitives (sub-surfaces) using both geometric and appearance features. The appearance characteristics of each learned anatomical primitive are then captured through a cascaded boosting learning method. (2) To effectively incorporate non-Gaussian shape priors, we cluster the training shapes in order to build multiple statistical shape models. (3) To our best knowledge, this is the first time the same segmentation algorithm has been directly employed in two very diverse applications: (a) Liver segmentation (closed surface) in PET-CT, in which CT has very low-resolution and low-contrast (b) Distal femur (condyle) surface (open surface) segmentation in MRI.