Frontotemporal interactions in face encoding and recognition. Cognition may result from different patterns of neural interactions distributed across the brain. If this is true then across different cognitive tasks different functional interactions should be observed within an anatomical network. To investigate this hypothesis, a network analysis of PET data obtained from a face memory study was conducted. PET scans were obtained while subjects performed face perception, face encoding and face recognition tasks. Partial least squares (PLS) analysis of rCBF was used to identify brain regions that were engaged during these tasks, and anatomically based structural equation modeling (SEM) was used to construct functional models for matching, encoding and recognition. There was some overlap in the functional interactions observed across the three cognitive tasks. In all three tasks, there were positive interactions involving the left occipitotemporal regions. These interactions may represent the perceptual component of the three tasks. Task-specific functional interactions were also observed. During face encoding, there was a bilateral positive influence of occipitotemporal regions on medial temporal regions. In addition, there were positive interhemispheric interactions between middle temporal regions and between limbic regions during encoding. These patterns may reflect the participation of medial temporal cortex in the formation of new memories. In the face recognition task, there was a positive loop in the right hemisphere from occipital cortex to frontal cortex and back from frontal cortex to occipitotemporal cortex. In addition, there was a strong positive input into the right hippocampal region from right occipitotemporal cortex. This pattern of interaction was specific to the recognition task and might represent the process whereby the input faces are compared to the internal representation laid down during encoding, thus enabling recognition.