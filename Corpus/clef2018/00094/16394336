Convergence study of an accelerated ML-EM algorithm using bigger step size. In SPECT/PET, the maximum-likelihood expectation-maximization (ML-EM) algorithm is getting more attention as the speed of computers increases. This is because it can incorporate various physical aspects into the reconstruction process leading to a more accurate reconstruction than other analytical methods such as filtered-backprojection algorithms. However, the convergence rate of the ML-EM algorithm is very slow. Several methods have been developed to speed it up, such as the ordered-subset expectation-maximization (OS-EM) algorithm. Even though OS-type algorithms can bring about significant acceleration in the iterative reconstruction, it is generally believed that ML-EM produces better images, in terms of statistical noise in the reconstruction. In this paper, we present an accelerated ML-EM algorithm with bigger step size and show its convergence characteristics in terms of variance noise and log-likelihood values. We also show some advantages of our method over other accelerating methods using additive forms.