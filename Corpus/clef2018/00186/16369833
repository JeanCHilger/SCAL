AO-classification of thoracic and lumbar fractures--reproducibility utilizing radiographs and clinical information. This study was designed to assess the inter-observer reliability and intra-observer reproducibility of standard radiographic evaluation of 150 thoraco-lumbar fractures using the AO-classification. The influence of clinical information on agreement levels was also evaluated. Six observers (two junior and four senior residents) evaluated the radiographic images. The injuries were classified by each observer as either type A, B or C according to the AO-classification system and the levels of agreement were documented. After 3 months the injuries were again classified with the addition of the clinical findings of each patient and the level of agreement evaluated. The level of agreement was measured using Cohen's kappa-test. The overall inter-observer agreement was rated as fair (0.291) in the first session and moderate (0.403) in the second. Intra-observer values ranged from slight (0.181) to moderate (0.488). The increased level of agreement in the second session was attributed to the value of additional clinical information, the learning curve of the junior residents and the simplicity of the classification.